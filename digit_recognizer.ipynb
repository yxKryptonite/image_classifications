{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This time we will implement a digit classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit-recognizer/test.csv\n",
      "digit-recognizer/train.csv\n",
      "digit-recognizer/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('digit-recognizer'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset:  32970000\n",
      "test dataset:  21952000\n"
     ]
    }
   ],
   "source": [
    "#读取csv数据，转为pandas数据\n",
    "digit_recon_train_csv = pd.read_csv('digit-recognizer/train.csv')\n",
    "digit_recon_test_csv = pd.read_csv('digit-recognizer/test.csv')\n",
    "\n",
    "print('train dataset: ', digit_recon_train_csv.size)\n",
    "print('test dataset: ', digit_recon_test_csv.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label shape:  (42000,)\n",
      "train image shape:  (42000, 784)\n",
      "test image shape:  (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "#将pandas数据转换为numpy\n",
    "train_label = digit_recon_train_csv.label.values\n",
    "train_image = digit_recon_train_csv.loc[:, digit_recon_train_csv.columns != 'label'].values / 255\n",
    "test_image = digit_recon_test_csv.values / 255\n",
    "\n",
    "print(\"train label shape: \", train_label.shape)\n",
    "print(\"train image shape: \", train_image.shape)\n",
    "print(\"test image shape: \", test_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (33600, 784)\n",
      "valid shape:  (8400, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_image, valid_image, train_label, valid_label = train_test_split(train_image,\n",
    "train_label,\n",
    "test_size=0.2,\n",
    "random_state=42)\n",
    "print(\"train shape: \", train_image.shape)\n",
    "print(\"valid shape: \", valid_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#可视化\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_image[80].reshape(28, 28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(train_label[80]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用pytorch构建data_loader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "\n",
    "train_image = torch.from_numpy(train_image)\n",
    "train_label = torch.from_numpy(train_label).type(torch.LongTensor)\n",
    "\n",
    "valid_image = torch.from_numpy(valid_image)\n",
    "valid_label = torch.from_numpy(valid_label).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = Data.TensorDataset(train_image, train_label)\n",
    "valid_dataset = Data.TensorDataset(valid_image, valid_label)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = Data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = Data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #利用pytorch构建模型，参考AlexNet\n",
    "# import torchvision\n",
    "# from torchvision import transforms\n",
    "# from torchvision import models\n",
    "\n",
    "# class MyNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MyNet, self).__init__()\n",
    "\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(8, 16, 3, 1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Conv2d(16, 16, 3, 1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(16, 8, 3, 1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2)\n",
    "#         )\n",
    "\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(8*7*7, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(256, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(256, 10)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, img):\n",
    "#         x = self.conv(img)\n",
    "#         o = self.fc(x.view(x.shape[0], -1))\n",
    "#         return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新构建模型，参考ResNet\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels, use_conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        if use_conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), \n",
    "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "def resnet_block(input_channels, num_channels, num_residuals, first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels, use_conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, \n",
    "                    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                    nn.Flatten(), nn.Linear(512, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/7\n",
      "loss is: 0.0041, train acc is: 92.4494, test acc is: 96.9405\n",
      "Epoch: 2/7\n",
      "loss is: 0.0011, train acc is: 97.9137, test acc is: 98.0357\n",
      "Epoch: 3/7\n",
      "loss is: 0.0007, train acc is: 98.5298, test acc is: 98.1190\n",
      "Epoch: 4/7\n",
      "loss is: 0.0006, train acc is: 98.8155, test acc is: 98.7143\n",
      "Epoch: 5/7\n",
      "loss is: 0.0004, train acc is: 99.0893, test acc is: 98.7024\n",
      "Epoch: 6/7\n",
      "loss is: 0.0004, train acc is: 99.2321, test acc is: 98.6786\n",
      "Epoch: 7/7\n",
      "loss is: 0.0003, train acc is: 99.3601, test acc is: 98.9405\n"
     ]
    }
   ],
   "source": [
    "#构建模型，并开始训练\n",
    "model = net\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "num_epoches = 7\n",
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_train_corr = 0.0\n",
    "    epoch_valid_corr = 0.0\n",
    "    print(\"Epoch: {}/{}\".format(epoch+1, num_epoches))\n",
    "\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = Variable(images.view(64, 1, 28, 28)).float()\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.data\n",
    "        outputs = torch.max(outputs.data, 1)[1]\n",
    "        epoch_train_corr += torch.sum(outputs == labels.data)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images = Variable(images.view(len(images), 1, 28, 28)).float()\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            outputs = model(images)\n",
    "            outputs = torch.max(outputs.data, 1)[1]\n",
    "            epoch_valid_corr += torch.sum(outputs == labels.data)\n",
    "\n",
    "    print(\"loss is: {:.4f}, train acc is: {:.4f}, test acc is: {:.4f}\".format(epoch_train_loss/len(train_dataset), 100*epoch_train_corr/len(train_dataset), 100*epoch_valid_corr/len(valid_dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_train_corr)\n",
    "plt.plot(epoch_valid_corr)\n",
    "plt.title('Accuracy in Training and Validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = np.zeros((test_image.shape[0], 2), dtype='int32')\n",
    "for i in range(test_image.shape[0]):\n",
    "    model.eval()\n",
    "    one_image = Variable(torch.from_numpy(test_image[i]).view(1, 1, 28, 28).float())\n",
    "    one_output = model(one_image)\n",
    "    test_results[i, 0] = i + 1\n",
    "    test_results[i, 1] = torch.max(one_output.data, 1)[1].numpy()\n",
    "\n",
    "Datas = {'ImageId': test_results[:, 0], 'Label': test_results[:, 1]}\n",
    "DataFrame = pd.DataFrame(Datas)\n",
    "DataFrame.to_csv('submission.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
